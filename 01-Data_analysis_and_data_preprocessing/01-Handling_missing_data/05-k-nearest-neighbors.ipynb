{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Data Analysis and Data Preprocessing\n",
    "\n",
    "## Section 1: Handling missing data\n",
    "\n",
    "### Part 5: K-Nearest Neighbors (KNN) Imputation\n",
    "\n",
    "In this part, we will explore the K-Nearest Neighbors (KNN) imputation technique applied to handle missing data. KNN imputation fills in missing values by using the values from neighboring data points.\n",
    "\n",
    "### 5.1 Understanding K-Nearest Neighbors (KNN) Imputation\n",
    "\n",
    "K-Nearest Neighbors (KNN) imputation is a technique that estimates missing values based on the values of their nearest neighbors. It assumes that similar data points have similar feature values. The algorithm finds the K nearest neighbors of a data point with missing values and imputes the missing values using the average or weighted average of the neighbors' values.\n",
    "\n",
    "The key idea behind KNN imputation is to leverage the similarity between data points to estimate missing values. By using the values of the nearest neighbors, the imputed values are expected to be closer to the true values.\n",
    "\n",
    "### 5.2 Training and Imputation\n",
    "\n",
    "To apply KNN imputation, we need a dataset with missing values. The algorithm identifies the nearest neighbors of each data point with missing values based on a distance metric, such as Euclidean distance. It then imputes the missing values using the average or weighted average of the neighbors' values.\n",
    "\n",
    "Scikit-Learn provides the KNNImputer class for performing KNN imputation. Here's an example of how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "np.random.seed(1)\n",
    "# Generate 25 random points for each category with distinct centers\n",
    "category1 = np.random.normal(loc=[0,0], scale=5, size=(25, 2))\n",
    "category2 = np.random.normal(loc=[50,50], scale=5, size=(25, 2))\n",
    "category3 = np.random.normal(loc=[100,100], scale=5, size=(25, 2))\n",
    "# Combine the points from each category\n",
    "data = np.vstack([category1, category2, category3])\n",
    "# Create labels for each category\n",
    "labels = np.repeat([1, 2, 3], 25)\n",
    "# Convert the NumPy array to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['X', 'Y'])\n",
    "df['Category'] = labels\n",
    "# Add 25 more random points to the dataset without category\n",
    "new_points = np.random.rand(25, 2) * 120  # Generate random points within the range (0, 120)\n",
    "df = pd.concat([df, pd.DataFrame(new_points, columns=['X', 'Y'])], ignore_index=True)\n",
    "\n",
    "# Create a KNNImputer instance\n",
    "imputer = KNNImputer(n_neighbors=25)\n",
    "# Impute the 'Category' column\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "# Convert the imputed 'Category' column to integers (1, 2, or 3)\n",
    "df_imputed['Category'] = df_imputed['Category'].round().astype(int)\n",
    "\n",
    "print(\"Original DataFrame\")\n",
    "print(df)\n",
    "print(\"DataFrame with Imputed Categories:\")\n",
    "print(df_imputed)\n",
    "\n",
    "# Scatter plot to visualize the 3 categories with NaN points\n",
    "plt.figure(figsize=(12, 6))  # Updated figsize to accommodate both plots side by side\n",
    "plt.subplot(1, 2, 1)  # Subplot 1: Scatter plot with NaN Categories\n",
    "plt.scatter(df[df['Category'] == 1]['X'], df[df['Category'] == 1]['Y'], label='Category 1', marker='o', s=100, color='blue')\n",
    "plt.scatter(df[df['Category'] == 2]['X'], df[df['Category'] == 2]['Y'], label='Category 2', marker='o', s=100, color='green')\n",
    "plt.scatter(df[df['Category'] == 3]['X'], df[df['Category'] == 3]['Y'], label='Category 3', marker='o', s=100, color='orange')\n",
    "# Mark NaN points with 'x'\n",
    "plt.scatter(df['X'][df['Category'].isnull()], df['Y'][df['Category'].isnull()], label='Unknown Category', marker='x', s=100, color='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot of 3 Categories with NaN Categories')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# Scatter plot to visualize the 3 categories with imputed categories\n",
    "plt.subplot(1, 2, 2)  # Subplot 2: Scatter plot with Imputed Categories\n",
    "plt.scatter(df_imputed[df_imputed['Category'] == 1]['X'], df_imputed[df_imputed['Category'] == 1]['Y'], label='Category 1', marker='o', s=100, color='blue')\n",
    "plt.scatter(df_imputed[df_imputed['Category'] == 2]['X'], df_imputed[df_imputed['Category'] == 2]['Y'], label='Category 2', marker='o', s=100, color='green')\n",
    "plt.scatter(df_imputed[df_imputed['Category'] == 3]['X'], df_imputed[df_imputed['Category'] == 3]['Y'], label='Category 3', marker='o', s=100, color='orange')\n",
    "plt.scatter(df_imputed['X'][df_imputed['Category'].isnull()], df_imputed['Y'][df_imputed['Category'].isnull()], label='Unknown Category', marker='x', s=100, color='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot of 3 Categories with Imputed Categories')\n",
    "plt.legend()    \n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example generates a dataset with three categories of points and introduces NaN categories to some points. Then, it uses the KNNImputer to predict the categories for the NaN points. The dataset is then plotted before and after the imputation process.\n",
    "The first subplot shows the scatter plot of 3 categories with NaN categories marked with 'x'. The second subplot shows the scatter plot of the same categories after imputing the NaN categories using KNNImputer.\n",
    "\n",
    "### 5.3 Choosing Parameters\n",
    "\n",
    "The KNNImputer class has several important parameters that need to be set appropriately. The n_neighbors parameter determines the number of neighbors to consider when imputing missing values. Other parameters include the distance metric and weights used in the imputation process.\n",
    "\n",
    "The value of k, the number of nearest neighbors to consider, significantly affects the model's performance. Choosing an optimal value for k requires careful consideration.\n",
    "\n",
    "- A small value of k can lead to high variance and overfitting.\n",
    "- A large value of k can lead to high bias and underfitting.\n",
    "\n",
    "### 5.4 Summary\n",
    "\n",
    "KNN imputation is a powerful technique for handling missing data. However, it requires that the dataset has a sufficient number of data points with complete information to estimate missing values accurately. Additionally, the choice of K and the distance metric can have a significant impact on the imputation results. Scikit-Learn provides the KNNImputer class for performing KNN imputation easily. Understanding the concepts, training, and parameter tuning is crucial for effectively using KNN imputation in practice.\n",
    "\n",
    "In the next part, we will explore how different machine learning models can solve missing data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
