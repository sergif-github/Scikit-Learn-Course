{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Data Analysis and Data Preprocessing\n",
    "\n",
    "## Section 2: Feature scaling and normalization\n",
    "\n",
    "### Part 3: Robust Scaling\n",
    "\n",
    "In this part, we will explore the concept of Robust scaling, a data preprocessing technique used to transform features by scaling them to be robust to outliers. Robust scaling is particularly useful when dealing with datasets that contain extreme values or outliers.\n",
    "\n",
    "### 3.1 Understanding Robust Scaling\n",
    "\n",
    "Robust scaling, also known as robust standardization, is a technique used to transform numerical features by scaling them based on robust statistics that are less affected by outliers. It involves subtracting the median and dividing by the interquartile range (IQR) of each feature.\n",
    "\n",
    "The RobustScaler uses the median and interquartile range (IQR) to scale the data, making it less sensitive to outliers. The median is used to center the data, and the IQR is used to scale it. The IQR is defined as the difference between the 75th percentile (Q3) and the 25th percentile (Q1) of the data.\n",
    "\n",
    "### 3.2 Using robust scaling\n",
    "\n",
    "To apply robust scaling, we need a dataset with numerical features. The scaling process involves calculating the median and IQR of each feature in the training set. We then subtract the median and divide by the IQR for each feature in both the training and test sets.\n",
    "\n",
    "Scikit-Learn provides the RobustScaler class for performing robust scaling. Here's an example of how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Sample dataset with a single feature (column)\n",
    "data = np.array([[1],\n",
    "                 [2],\n",
    "                 [3],\n",
    "                 [4],\n",
    "                 [5],\n",
    "                 [100]])\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "\n",
    "# Create a RobustScaler object to robustly scale the data\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the RobustScaler to the data and compute the median and IQR for scaling\n",
    "scaler.fit(data)\n",
    "\n",
    "# Transform the data using the learned parameters for robust scaling\n",
    "scaled_data = scaler.transform(data)\n",
    "\n",
    "print(\"\\nRobustly Scaled Data:\")\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we created a sample dataset with a single feature and six samples. One of the samples (100) is an outlier, which could significantly impact scaling if we use StandardScaler or MinMaxScaler. Instead, we used the RobustScaler to scale the data robustly.\n",
    "\n",
    "### 3.3 Summary\n",
    "\n",
    "Robust scaling is a data preprocessing technique used to transform numerical features by scaling them based on robust statistics. The key idea behind robust scaling is to bring all features to a common scale while minimizing the influence of outliers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
