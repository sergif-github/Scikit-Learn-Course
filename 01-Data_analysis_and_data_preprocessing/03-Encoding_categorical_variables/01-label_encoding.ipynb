{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Data Analysis and Data Preprocessing\n",
    "\n",
    "## Section 3: Encoding categorical variables\n",
    "\n",
    "### Part 1: Label Encoding\n",
    "\n",
    "Label Encoding is a data preprocessing technique used to convert categorical variables into numerical labels. Label Encoding is particularly useful when working with algorithms that require numeric inputs.\n",
    "\n",
    "### 1.1 Understanding Label Encoding\n",
    "\n",
    "Label Encoding assigns a unique integer value to each category in a categorical variable, allowing algorithms to work with the numerical representations. Label Encoding is suitable for categorical variables with an inherent ordinal relationship, such as \"low,\" \"medium,\" and \"high.\"\n",
    "\n",
    "The key idea behind Label Encoding is to transform categorical variables into a numerical format that algorithms can process. It does not introduce any additional columns or dimensions like One-Hot Encoding. Instead, it replaces each category with a unique integer label.\n",
    "\n",
    "Label encoding is appropriate for ordinal data (data with an inherent order) or nominal data (data without any inherent order).\n",
    "\n",
    "For nominal data, label encoding might introduce ordinality, leading to incorrect interpretations by some algorithms. In such cases, one-hot encoding (dummy variables) is a preferred method.\n",
    "\n",
    "### 1.2 Using Label Encoding\n",
    "\n",
    "To apply Label Encoding, we need a dataset with categorical variables. The encoding process involves mapping each category in a categorical variable to a unique integer label. The mapping is typically based on the alphabetical order of the categories or the order of appearance in the dataset.\n",
    "\n",
    "Here's an example of how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample categorical data\n",
    "data = ['red', 'blue', 'green', 'green', 'red', 'blue']\n",
    "\n",
    "# Create the LabelEncoder object\n",
    "encoder = LabelEncoder()\n",
    "# Fit and transform the data using LabelEncoder\n",
    "encoded_data = encoder.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\", data)\n",
    "print(\"Encoded Data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have a list of colors ('red', 'blue', and 'green'). After applying Label Encoding, the colors are encoded into integers: 'red' becomes 2, 'blue' becomes 0, and 'green' becomes 1.\n",
    "\n",
    "### 1.3 Inverse Transformation\n",
    "\n",
    "In some cases, you may need to convert the encoded labels back to their original categorical form. Scikit-Learn's LabelEncoder provides the inverse_transform method for reversing the encoding process and obtaining the original categories from the encoded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample categorical data\n",
    "data = ['red', 'blue', 'green', 'green', 'red', 'blue']\n",
    "print(\"Original Data:\", data)\n",
    "\n",
    "# Create the LabelEncoder object\n",
    "encoder = LabelEncoder()\n",
    "# Fit and transform the data using LabelEncoder\n",
    "encoded_data = encoder.fit_transform(data)\n",
    "# Print the encoded data\n",
    "print(\"Encoded Data:\", encoded_data)\n",
    "\n",
    "# Inverse transform the encoded data back to original categorical values\n",
    "decoded_data = encoder.inverse_transform(encoded_data)\n",
    "# Print the decoded data\n",
    "print(\"Decoded Data:\", decoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have a list of colors ('red', 'blue', and 'green'). After applying Label Encoding, the colors are encoded into integers: 'red' becomes 2, 'blue' becomes 0, and 'green' becomes 1.\n",
    "The inverse_transform method of LabelEncoder can be used to transform the encoded data back to the original categorical values. As we can see in the output, the decoded data is the same as the original data before encoding.\n",
    "\n",
    "### 1.4 Conclusion\n",
    "\n",
    "Label Encoding is a data preprocessing technique used to convert categorical variables into numerical labels. It assigns a unique integer value to each category, allowing algorithms to work with the numerical representations. Scikit-Learn provides the LabelEncoder class for performing Label Encoding easily. Understanding the concepts, training, and handling of categorical variables is crucial for effectively using Label Encoding in practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
